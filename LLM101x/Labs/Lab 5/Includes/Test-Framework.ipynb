{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8f225bc9-136b-49ac-a79f-4d17c31d6d1c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(\"Importing lab testing framework.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8320676e-350a-4f53-926e-9f4a8ba1e936",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# DEFINING HELPER FUNCTIONS\n",
    "\n",
    "def createDirStructure():\n",
    "  '''\n",
    "  This creates the directories needed for the test handler.\n",
    "  Note that `lesson_question_d` is lesson num: num of questions.\n",
    "    Modify this when changing the number of questions\n",
    "  '''\n",
    "  from pathlib import Path\n",
    "\n",
    "  lesson_question_d = {\n",
    "    1: 3, # TODO: confirm these questions once tests are finalized \n",
    "    2: 6,\n",
    "    3: 4,\n",
    "    4: 9,\n",
    "    5: 5,\n",
    "  }\n",
    "  path = getUsernameFromEnv(\"\")\n",
    "\n",
    "  for lesson, questions in lesson_question_d.items():\n",
    "    for question in range(1, questions+1):\n",
    "      final_path = f\"{path}lesson{lesson}/question{question}\"\n",
    "      Path(final_path).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def questionPassed(userhome_for_testing, lesson, question):\n",
    "  '''\n",
    "  Helper function that writes an empty file named `PASSED` to the designated path\n",
    "  '''\n",
    "  from pathlib import Path\n",
    "\n",
    "  print(f\"\\u001b[32mPASSED\\x1b[0m: All tests passed for {lesson}, {question}\")\n",
    "\n",
    "  path = f\"{userhome_for_testing}/{question}\"\n",
    "  Path(path).mkdir(parents=True, exist_ok=True)\n",
    "  with open(f\"{path}/PASSED\", \"wb\") as handle:\n",
    "      pass # just write an empty file\n",
    "  \n",
    "  print (\"\\u001b[32mRESULTS RECORDED\\x1b[0m: Click `Submit` when all questions are completed to log the results.\")\n",
    "\n",
    "def getUsernameFromEnv(lesson):\n",
    "  '''\n",
    "  Exception handling for when the working directory is not in the scope\n",
    "  (i.e. the Classroom-Setup was not run)\n",
    "  '''\n",
    "  try:\n",
    "    return f\"{DA.paths.working_dir}-testing-files/{lesson}\"\n",
    "  except NameError:\n",
    "    raise NameError(\"Working directory not found. Please re-run the Classroom-Setup at the beginning of the notebook.\")\n",
    "\n",
    "createDirStructure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3fc41211-e2f1-45af-888a-7c2d672624f9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LLM 01L - LLMs with Hugging Face Lab\n",
    "\n",
    "def dbTestQuestion1_1(summarizer, summarization_results, summarizer_inputs):\n",
    "  lesson, question = \"lesson1\", \"question1\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(summarizer.task) == \"summarization\", \"Test NOT passed: Pipeline should be built for task `summarization`\"\n",
    "  assert isinstance(summarization_results, list), \"Test NOT passed: Result should be a list.\"\n",
    "  assert len(summarization_results) == len(summarizer_inputs), \"Test NOT passed: Result should be a list of length equal to the input dataset size.\"\n",
    "  assert min([len(s) for s in summarization_results]) > 0, \"Test NOT passed: Summaries should be non-empty.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion1_2(translation_pipeline, translation_results, translation_inputs):\n",
    "  lesson, question = \"lesson1\", \"question2\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert \"translation\" in str(translation_pipeline.task), \"Test NOT passed: Pipeline should be built for task `translation`\"\n",
    "  assert isinstance(translation_results, list), \"Test NOT passed: Result should be a list.\"\n",
    "  assert len(translation_results) == len(translation_inputs), \"Test NOT passed: Result should be a list of length equal to the input dataset size.\"\n",
    "  assert min([len(s) for s in translation_results]) > 0, \"Test NOT passed: Translations should be non-empty.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion1_3(few_shot_pipeline, few_shot_prompt, few_shot_results):\n",
    "  lesson, question = \"lesson1\", \"question3\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert isinstance(few_shot_prompt, str), \"Test NOT passed: Prompt should be a string.\"\n",
    "  assert isinstance(few_shot_results, str), \"Test NOT passed: Results should be a string.\"\n",
    "  assert len(few_shot_prompt) > 0, \"Test NOT passed: Prompt should be non-empty.\"\n",
    "  assert few_shot_results.find(few_shot_prompt) == 0, \"Test NOT passed: Results should be prefixed by the prompt.\"\n",
    "  assert len(few_shot_results) > len(few_shot_prompt), \"Test NOT passed: Results should include new text, beyond the prompt.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "be79d9e3-df59-4498-bb03-3d87a32602ff",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LLM 02L - Embeddings, Vector Databases, and Search\n",
    "\n",
    "def dbTestQuestion2_1(collection_name):\n",
    "  lesson, question = \"lesson2\", \"question1\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  collection_name==\"my_talks\", \"Test NOT passed: The collection_name should be my_talks.\" \n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion2_2(talks_collection):\n",
    "  lesson, question = \"lesson2\", \"question2\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  str(type(talks_collection)) == \"<class 'chromadb.api.models.Collection.Collection'>\", \"Test NOT passed: Result should be of type `chromadb.api.models.Collection.Collection`\"\n",
    "\n",
    "  assert talks_collection.count() > 0, \"Test NOT passed: The collection should be non-empty.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion2_3(results):\n",
    "  lesson, question = \"lesson2\", \"question3\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  len(results) > 0, \"Test NOT passed: The result must be non-empty, check `query_texts` and `n_results`\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion2_4(pipe):\n",
    "  lesson, question = \"lesson2\", \"question4\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  str(type(pipe)) == \"<class 'transformers.pipelines.text_generation.TextGenerationPipeline'>\", \"Test NOT passed: Result should be of type `transformers.pipelines.text_generation.TextGenerationPipeline`\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion2_5(_question, context, prompt_template):\n",
    "  # using _question given that `question` is reserved for `questionPassed`\n",
    "  lesson, question = \"lesson2\", \"question5\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert isinstance(_question, str), \"Test NOT passed: `question` should be a `str` type.\"\n",
    "  assert isinstance(context, str), \"Test NOT passed: `context` should be a `str` type.\"\n",
    "  assert _question in prompt_template, \"Test NOT passed: Your `question` should appear inside the prompt.\" \n",
    "  assert context in prompt_template, \"Test NOT passed: Your `context` should appear inside the prompt.\" \n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion2_6(lm_response):\n",
    "  lesson, question = \"lesson2\", \"question6\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert lm_response[0][\"generated_text\"] is not None, \"Test NOT passed:  `lm_response` should not be empty\" \n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "82d7e1ae-3cf5-4959-9456-34377f6896a9",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LLM 03L - Building LLM Chains Lab\n",
    "\n",
    "def dbTestQuestion3_1(embeddings, docsearch):\n",
    "  lesson, question = \"lesson3\", \"question1\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(embeddings)) == \"<class 'langchain.embeddings.huggingface.HuggingFaceEmbeddings'>\", \"Test NOT passed: Result is not of type `langchain.embeddings.huggingface.HuggingFaceEmbeddings`\"\n",
    "  assert str(type(docsearch)) == \"<class 'langchain.vectorstores.chroma.Chroma'>\", \"Test NOT passed: Result is not of type `langchain.vectorstores.chroma.Chroma`\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion3_2(qa, query_results_hamlet):\n",
    "  lesson, question = \"lesson3\", \"question2\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(qa)) == \"<class 'langchain.chains.retrieval_qa.base.RetrievalQA'>\", \"Test NOT passed: Result is not of type `langchain.chains.retrieval_qa.base.RetrievalQA`\"\n",
    "  assert type(query_results_hamlet) == str, \"Test NOT passed: Query results not a string\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion3_3(qa, query_results_venice):\n",
    "  lesson, question = \"lesson3\", \"question3\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(qa)) == \"<class 'langchain.chains.retrieval_qa.base.RetrievalQA'>\", \"Test NOT passed: Result is not of type `langchain.chains.retrieval_qa.base.RetrievalQA`\"\n",
    "  assert type(query_results_venice) == str, \"Test NOT passed: Query results not a string\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion3_4(qa, query_results_romeo):\n",
    "  lesson, question = \"lesson3\", \"question4\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(qa)) == \"<class 'langchain.chains.retrieval_qa.base.RetrievalQA'>\", \"Test NOT passed: Result is not of type `langchain.chains.retrieval_qa.base.RetrievalQA`\"\n",
    "  assert type(query_results_romeo) == str, \"Test NOT passed: Query results not a string\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d3235854-2d16-436b-aeb3-94577cfb7ead",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# LLM 04L - Fine-tuning LLMs\n",
    "\n",
    "def dbTestQuestion4_1(ds):\n",
    "  lesson, question = \"lesson4\", \"question1\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(ds.keys()) == \"dict_keys(['train'])\", \"Test NOT passed: `ds` should be of type `datasets.dataset_dict.DatasetDict`\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion4_2(model_checkpoint):\n",
    "  lesson, question = \"lesson4\", \"question2\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  model_checkpoint == \"EleutherAI/pythia-70m-deduped\", \"Test NOT passed: `model_checkpoint` should be `EleutherAI/pythia-70m-deduped`.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion4_3(tokenizer):\n",
    "  lesson, question = \"lesson4\", \"question3\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(tokenizer)) == \"<class 'transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast'>\", \"Test NOT passed: `tokenizer` is not of type `transformers.models.gpt_neox.tokenization_gpt_neox_fast.GPTNeoXTokenizerFast`\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_4(tokenized_dataset):\n",
    "  lesson, question = \"lesson4\", \"question4\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert str(type(tokenized_dataset)) == \"<class 'datasets.dataset_dict.DatasetDict'>\", \"Test NOT passed: `tokenized_dataset` should be of type `datasets.dataset_dict.DatasetDict`\"\n",
    "  assert  len(tokenized_dataset[\"train\"][\"input_ids\"][0]) == len(tokenized_dataset[\"train\"][\"attention_mask\"][0]), \"Test NOT passed: For each entry the number of `input_ids` and `attention_masks` should be equal\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_5(training_args):\n",
    "  lesson, question = \"lesson4\", \"question5\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert training_args.num_train_epochs == 10, \"Test NOT passed: `num_train_epochs` should be 10.\"\n",
    "  assert str(type(training_args.optim)) == \"<enum 'OptimizerNames'>\", \"Test NOT passed: `optim` should be of type `OptimizerNames`.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_6(model):\n",
    "  lesson, question = \"lesson4\", \"question6\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert model.base_model_prefix == \"gpt_neox\", \"Test NOT passed: `base_model_prefix should be `gpt_neox`, reload your model checkpoint.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_7(trainer):\n",
    "  lesson, question = \"lesson4\", \"question7\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert trainer.train_dataset.num_rows == 6000, \"Test NOT passed: The number of rows in the training data is not equal to `TRAINING_SIZE`.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_8(trainer):\n",
    "  lesson, question = \"lesson4\", \"question8\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert trainer.state.epoch == 10.0, \"Test NOT passed: make sure to run your training for 10 epochs exactly.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) \n",
    "\n",
    "def dbTestQuestion4_9(rouge_scores):\n",
    "  lesson, question = \"lesson4\", \"question9\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert type(rouge_scores) == dict, \"Test NOT passed: `rouge_scores should be a dict, check your scoring answer.\"\n",
    "  \n",
    "  questionPassed(userhome_for_testing, lesson, question) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "92375113-d1eb-4cca-abf7-b8d4dc944dcf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# #LLM 05L - LLMs and Society Lab\n",
    "\n",
    "def dbTestQuestion5_1(group1_bold, group2_bold):\n",
    "  lesson, question = \"lesson5\", \"question1\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert  isinstance(group1_bold, list), \"Test NOT passed: `group1_bold` should be of type list.\"\n",
    "  assert  isinstance(group2_bold, list), \"Test NOT passed: `group2_bold` should be of type list.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion5_2(group1_prompts, group2_prompts):\n",
    "  lesson, question = \"lesson5\", \"question2\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert isinstance(group1_prompts, list), \"Test NOT passed: `group1_prompts` should be of type list.\"\n",
    "  assert isinstance(group2_prompts, list), \"Test NOT passed: `group2_prompts` should be of type list.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion5_3(group1_continuation, group2_continuation):\n",
    "  lesson, question = \"lesson5\", \"question3\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert isinstance(group1_continuation, list), \"Test NOT passed: `group1_continuation` should be of type list.\"\n",
    "  assert isinstance(group2_continuation, list), \"Test NOT passed: `group2_continuation` should be of type list.\"\n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question)\n",
    "\n",
    "def dbTestQuestion5_4(regard_score):\n",
    "  lesson, question = \"lesson5\", \"question4\"\n",
    "  userhome_for_testing = getUsernameFromEnv(lesson)\n",
    "\n",
    "  assert isinstance(regard_score, dict), \"Test NOT passed: The regard score should be of type dictionary.\" \n",
    "\n",
    "  questionPassed(userhome_for_testing, lesson, question) \n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Test-Framework",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
